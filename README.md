# learning-log
My learning journey

# ðŸ“˜ Day 1 â€” The Journey Begins

ðŸŽ¯ **First goal:** Learn the basics of statistics â€” the language behind data.  
Tiny steps today, but every journey begins with them.

### ðŸ“š Today I learned:
- âœ”ï¸ The **mean** (arithmetic average)
- âœ”ï¸ The **median**, **percentiles**, and **quartiles**  
- âœ”ï¸ **Outliers** â€” the unexpected or extreme values  
- âœ”ï¸ The **minimum** and **maximum**

Itâ€™s a small beginning, but every bit matters.  
Onward. ðŸš€

# ðŸ“˜ Day 2 â€” Diving Deeper into Dispersion

ðŸ“ˆ **Still on my first goal:** Building a strong foundation in statistics.  
Today's focus: understanding how data varies, spreads, and where it sits.

### ðŸ“š Today I learned:

- âœ”ï¸ **Mean** â€” average value  
  â†’ `np.mean(data)`

- âœ”ï¸ **Median** â€” middle value in sorted data  
  â†’ `np.median(data)`

- âœ”ï¸ **Mode** â€” most frequent value  
  â†’ `stats.mode(data)`

- âœ”ï¸ **Variance** â€” average of squared deviations from the mean  
  â†’ `np.var(data)`

- âœ”ï¸ **Standard deviation (std)** â€” average deviation from the mean  
  â†’ `np.std(data)`

- âœ”ï¸ **Coefficient of variation (V)** â€” relative variability  
  â†’ `V = np.std(data) np.mean(data)`  
  â†’ `np.std(data) / np.mean(data)`

- âœ”ï¸ **Range (R)** â€” difference between max and min  
  â†’ `R = max - min`  
  â†’ `np.max(data) - np.min(data)`

- âœ”ï¸ **Interquartile range (IQR)** â€” spread of the middle 50%  
  â†’ `IQR = Q3 - Q1`  
  â†’ `np.percentile(data, 75) - np.percentile(data, 25)`

- âœ”ï¸ **Quartile deviation (Q)** â€” half of IQR  
  â†’ `Q = IQR / 2`

- âœ”ï¸ **Quartile coefficient of variation (Vq)** â€” quartile-based relative variation  
  â†’ `Vq = Q / median`

> Bonus: Plotted a histogram using `df["col"].hist()` â€” a fast and handy pandas shortcut.

ðŸ§° **Working with libraries:**  
`numpy`, `pandas`, `matplotlib`, `scipy`

Each new term sharpens the picture. More tools, better insights.  
Onward. ðŸš€

# ðŸ“˜ Day 3 â€” Exploring Distributions and Normalization

ðŸ“ˆ **Still on my first goal:** Deepening my understanding of statistical distributions.  
Today I focused on distribution shapes, skewness, and normalization techniques.

### ðŸ“š Today I learned:

- âœ”ï¸ **Normal distribution** â€” classic bell-shaped curve  

- âœ”ï¸ **Skewness** â€” measure of asymmetry in a distribution  
  - **Right-skewed (positive skewness)** â€” tail to the right  
  - **Left-skewed (negative skewness)** â€” tail to the left  
  â†’ `scipy.stats.skew(data)`

- âœ”ï¸ **Long-tail distribution** â€” distributions with heavy tails

- âœ”ï¸ **Normalization techniques**:
  - **Log transformation** â€” `np.log_2_10(data)`
  - **Box-Cox transformation** â€” `boxcox(data)`
  - **Square root transformation** â€” `np.sqrt(data)`


- âœ”ï¸ **Histograms** â€” visualize data distribution  
  â†’ `df["column"].hist()`

- âœ”ï¸ **Boxplots (box-and-whisker plots)** â€” visualize spread, median, and outliers  
  â†’ `df.boxplot(vert=False, figsize=(15, 5));`
  ![image](https://github.com/user-attachments/assets/8356f31c-75cd-4b64-8af2-4d659caab645)


ðŸ§° **Working with libraries:**  
`numpy`, `pandas`, `scipy`, `matplotlib`

> Configured pandas output for better readability:  
> `pd.set_option('display.float_format', lambda x: '%.3f' % x)`

Each adjustment to data reveals a little more of its hidden structure.  
Onward. ðŸš€

# ðŸ“˜ Day 4 â€” Understanding Data Types

ðŸ“ˆ **Still on my first goal:** Strengthening my statistical foundation.  
Today I explored different types of data and how to work with them properly.

### ðŸ“š Today I learned:

1. I learned to differentiate between **numerical** and **categorical** types of data.
2. I understood that **numerical data** is best analyzed using statistical measures such as mean, median, and standard deviation.
3. I learned that **categorical data** should be analyzed by counting occurrences, calculating participation percentages, and identifying unique values.
4. I practiced **visualizing categorical data** using **bar charts**.
5. I realized the importance of **recognizing data types early** because **different types require different analytical approaches**.

ðŸ§° **Working with libraries:**  
`numpy`, `pandas`, `matplotlib`

---
Even though today's notes look shorter, it was one of the most challenging and practical days so far.  
I spent a lot of time applying theory to real examples and reinforcing my understanding.

Each new layer of understanding builds stronger foundations.  
Onward. ðŸš€
